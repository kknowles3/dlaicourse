{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NLP_Week4_Exercise_Shakespeare_Question.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BOwsuGQQY9OL",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "### YOUR CODE HERE\n",
        "import tensorflow.keras.regularizers as kr\n",
        "# Figure out how to import regularizers\n",
        "###\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PRnDnCW-Z7qv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c6ebc8ec-2ba7-4c61-f955-01e2d9db59f1"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-04-08 22:04:31--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.68.128, 2404:6800:4003:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.68.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93578 (91K) [text/plain]\n",
            "Saving to: ‘/tmp/sonnets.txt’\n",
            "\n",
            "\r/tmp/sonnets.txt      0%[                    ]       0  --.-KB/s               \r/tmp/sonnets.txt    100%[===================>]  91.38K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2020-04-08 22:04:32 (102 MB/s) - ‘/tmp/sonnets.txt’ saved [93578/93578]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9vH8Y59ajYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "77c64d56-fc99-4395-ddf0-5166784ce5e0"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences=True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(150))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=kr.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "# Pick an optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_5 (Embedding)      (None, 10, 100)           321100    \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 10, 300)           301200    \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 10, 300)           0         \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 150)               270600    \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1605)              242355    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 3211)              5156866   \n",
            "=================================================================\n",
            "Total params: 6,292,121\n",
            "Trainable params: 6,292,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AIg2f1HBxqof",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f1a41f6a-a963-48c8-9d59-7a35da1bbe15"
      },
      "source": [
        " history = model.fit(predictors, label, epochs=200, verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.1258 - accuracy: 0.8076\n",
            "Epoch 2/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.1202 - accuracy: 0.8005\n",
            "Epoch 3/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0966 - accuracy: 0.8089\n",
            "Epoch 4/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0873 - accuracy: 0.8125\n",
            "Epoch 5/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0885 - accuracy: 0.8100\n",
            "Epoch 6/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0942 - accuracy: 0.8073\n",
            "Epoch 7/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0969 - accuracy: 0.8086\n",
            "Epoch 8/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0816 - accuracy: 0.8088\n",
            "Epoch 9/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0551 - accuracy: 0.8149\n",
            "Epoch 10/200\n",
            "484/484 [==============================] - 6s 11ms/step - loss: 1.0416 - accuracy: 0.8150\n",
            "Epoch 11/200\n",
            "484/484 [==============================] - 6s 12ms/step - loss: 1.0445 - accuracy: 0.8113\n",
            "Epoch 12/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0264 - accuracy: 0.8183\n",
            "Epoch 13/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0342 - accuracy: 0.8157\n",
            "Epoch 14/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0621 - accuracy: 0.8097\n",
            "Epoch 15/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0273 - accuracy: 0.8138\n",
            "Epoch 16/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0142 - accuracy: 0.8189\n",
            "Epoch 17/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0068 - accuracy: 0.8204\n",
            "Epoch 18/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0134 - accuracy: 0.8178\n",
            "Epoch 19/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 1.0032 - accuracy: 0.8209\n",
            "Epoch 20/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9933 - accuracy: 0.8199\n",
            "Epoch 21/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9932 - accuracy: 0.8211\n",
            "Epoch 22/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9788 - accuracy: 0.8233\n",
            "Epoch 23/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9833 - accuracy: 0.8223\n",
            "Epoch 24/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9957 - accuracy: 0.8208\n",
            "Epoch 25/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9822 - accuracy: 0.8194\n",
            "Epoch 26/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9711 - accuracy: 0.8229\n",
            "Epoch 27/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9582 - accuracy: 0.8259\n",
            "Epoch 28/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9470 - accuracy: 0.8292\n",
            "Epoch 29/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9507 - accuracy: 0.8252\n",
            "Epoch 30/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9534 - accuracy: 0.8256\n",
            "Epoch 31/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9530 - accuracy: 0.8236\n",
            "Epoch 32/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9436 - accuracy: 0.8273\n",
            "Epoch 33/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9397 - accuracy: 0.8262\n",
            "Epoch 34/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9518 - accuracy: 0.8236\n",
            "Epoch 35/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9540 - accuracy: 0.8204\n",
            "Epoch 36/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9313 - accuracy: 0.8268\n",
            "Epoch 37/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9148 - accuracy: 0.8314\n",
            "Epoch 38/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9152 - accuracy: 0.8309\n",
            "Epoch 39/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9107 - accuracy: 0.8299\n",
            "Epoch 40/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9095 - accuracy: 0.8302\n",
            "Epoch 41/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8976 - accuracy: 0.8322\n",
            "Epoch 42/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9121 - accuracy: 0.8285\n",
            "Epoch 43/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9051 - accuracy: 0.8319\n",
            "Epoch 44/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9102 - accuracy: 0.8277\n",
            "Epoch 45/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9108 - accuracy: 0.8269\n",
            "Epoch 46/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9127 - accuracy: 0.8273\n",
            "Epoch 47/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9072 - accuracy: 0.8298\n",
            "Epoch 48/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.9042 - accuracy: 0.8260\n",
            "Epoch 49/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8831 - accuracy: 0.8331\n",
            "Epoch 50/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8844 - accuracy: 0.8313\n",
            "Epoch 51/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8825 - accuracy: 0.8307\n",
            "Epoch 52/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8882 - accuracy: 0.8309\n",
            "Epoch 53/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8832 - accuracy: 0.8300\n",
            "Epoch 54/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8867 - accuracy: 0.8289\n",
            "Epoch 55/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8845 - accuracy: 0.8306\n",
            "Epoch 56/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8757 - accuracy: 0.8348\n",
            "Epoch 57/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8906 - accuracy: 0.8264\n",
            "Epoch 58/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8751 - accuracy: 0.8317\n",
            "Epoch 59/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8780 - accuracy: 0.8311\n",
            "Epoch 60/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8620 - accuracy: 0.8333\n",
            "Epoch 61/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8638 - accuracy: 0.8342\n",
            "Epoch 62/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8632 - accuracy: 0.8315\n",
            "Epoch 63/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8686 - accuracy: 0.8305\n",
            "Epoch 64/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8606 - accuracy: 0.8357\n",
            "Epoch 65/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8522 - accuracy: 0.8345\n",
            "Epoch 66/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8642 - accuracy: 0.8320\n",
            "Epoch 67/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8583 - accuracy: 0.8325\n",
            "Epoch 68/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8435 - accuracy: 0.8360\n",
            "Epoch 69/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8476 - accuracy: 0.8339\n",
            "Epoch 70/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8523 - accuracy: 0.8310\n",
            "Epoch 71/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8489 - accuracy: 0.8345\n",
            "Epoch 72/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8538 - accuracy: 0.8311\n",
            "Epoch 73/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8424 - accuracy: 0.8331\n",
            "Epoch 74/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8405 - accuracy: 0.8335\n",
            "Epoch 75/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8425 - accuracy: 0.8339\n",
            "Epoch 76/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8555 - accuracy: 0.8302\n",
            "Epoch 77/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8410 - accuracy: 0.8346\n",
            "Epoch 78/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8308 - accuracy: 0.8362\n",
            "Epoch 79/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8379 - accuracy: 0.8327\n",
            "Epoch 80/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8301 - accuracy: 0.8362\n",
            "Epoch 81/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8449 - accuracy: 0.8330\n",
            "Epoch 82/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8392 - accuracy: 0.8330\n",
            "Epoch 83/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8230 - accuracy: 0.8363\n",
            "Epoch 84/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8213 - accuracy: 0.8355\n",
            "Epoch 85/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8206 - accuracy: 0.8375\n",
            "Epoch 86/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8287 - accuracy: 0.8349\n",
            "Epoch 87/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8201 - accuracy: 0.8379\n",
            "Epoch 88/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8417 - accuracy: 0.8319\n",
            "Epoch 89/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8407 - accuracy: 0.8289\n",
            "Epoch 90/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8287 - accuracy: 0.8330\n",
            "Epoch 91/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8291 - accuracy: 0.8321\n",
            "Epoch 92/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8184 - accuracy: 0.8367\n",
            "Epoch 93/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8260 - accuracy: 0.8339\n",
            "Epoch 94/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8236 - accuracy: 0.8351\n",
            "Epoch 95/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8055 - accuracy: 0.8375\n",
            "Epoch 96/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8289 - accuracy: 0.8303\n",
            "Epoch 97/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8280 - accuracy: 0.8326\n",
            "Epoch 98/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.8092 - accuracy: 0.8370\n",
            "Epoch 99/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8031 - accuracy: 0.8360\n",
            "Epoch 100/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8237 - accuracy: 0.8319\n",
            "Epoch 101/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8206 - accuracy: 0.8344\n",
            "Epoch 102/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8061 - accuracy: 0.8373\n",
            "Epoch 103/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8063 - accuracy: 0.8357\n",
            "Epoch 104/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7976 - accuracy: 0.8371\n",
            "Epoch 105/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8045 - accuracy: 0.8362\n",
            "Epoch 106/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8080 - accuracy: 0.8355\n",
            "Epoch 107/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7945 - accuracy: 0.8367\n",
            "Epoch 108/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.8010 - accuracy: 0.8344\n",
            "Epoch 109/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8079 - accuracy: 0.8338\n",
            "Epoch 110/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8066 - accuracy: 0.8363\n",
            "Epoch 111/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7927 - accuracy: 0.8375\n",
            "Epoch 112/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7974 - accuracy: 0.8360\n",
            "Epoch 113/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7871 - accuracy: 0.8388\n",
            "Epoch 114/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7847 - accuracy: 0.8393\n",
            "Epoch 115/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7956 - accuracy: 0.8398\n",
            "Epoch 116/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7895 - accuracy: 0.8381\n",
            "Epoch 117/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.8095 - accuracy: 0.8331\n",
            "Epoch 118/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7878 - accuracy: 0.8366\n",
            "Epoch 119/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8054 - accuracy: 0.8356\n",
            "Epoch 120/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8003 - accuracy: 0.8339\n",
            "Epoch 121/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.8015 - accuracy: 0.8354\n",
            "Epoch 122/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7981 - accuracy: 0.8336\n",
            "Epoch 123/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7918 - accuracy: 0.8345\n",
            "Epoch 124/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7786 - accuracy: 0.8384\n",
            "Epoch 125/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7839 - accuracy: 0.8360\n",
            "Epoch 126/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7839 - accuracy: 0.8379\n",
            "Epoch 127/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7830 - accuracy: 0.8355\n",
            "Epoch 128/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7736 - accuracy: 0.8397\n",
            "Epoch 129/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7724 - accuracy: 0.8402\n",
            "Epoch 130/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7817 - accuracy: 0.8375\n",
            "Epoch 131/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7853 - accuracy: 0.8357\n",
            "Epoch 132/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7963 - accuracy: 0.8349\n",
            "Epoch 133/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7915 - accuracy: 0.8348\n",
            "Epoch 134/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7947 - accuracy: 0.8334\n",
            "Epoch 135/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7778 - accuracy: 0.8385\n",
            "Epoch 136/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7674 - accuracy: 0.8391\n",
            "Epoch 137/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7745 - accuracy: 0.8380\n",
            "Epoch 138/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7841 - accuracy: 0.8364\n",
            "Epoch 139/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7833 - accuracy: 0.8363\n",
            "Epoch 140/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7730 - accuracy: 0.8384\n",
            "Epoch 141/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7735 - accuracy: 0.8395\n",
            "Epoch 142/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7790 - accuracy: 0.8367\n",
            "Epoch 143/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7736 - accuracy: 0.8388\n",
            "Epoch 144/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7716 - accuracy: 0.8389\n",
            "Epoch 145/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7760 - accuracy: 0.8371\n",
            "Epoch 146/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7743 - accuracy: 0.8380\n",
            "Epoch 147/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7775 - accuracy: 0.8356\n",
            "Epoch 148/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7651 - accuracy: 0.8382\n",
            "Epoch 149/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7730 - accuracy: 0.8353\n",
            "Epoch 150/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7791 - accuracy: 0.8350\n",
            "Epoch 151/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7791 - accuracy: 0.8357\n",
            "Epoch 152/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7633 - accuracy: 0.8392\n",
            "Epoch 153/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7613 - accuracy: 0.8395\n",
            "Epoch 154/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7653 - accuracy: 0.8379\n",
            "Epoch 155/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7740 - accuracy: 0.8360\n",
            "Epoch 156/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7710 - accuracy: 0.8362\n",
            "Epoch 157/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7765 - accuracy: 0.8358\n",
            "Epoch 158/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7667 - accuracy: 0.8378\n",
            "Epoch 159/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7604 - accuracy: 0.8384\n",
            "Epoch 160/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7659 - accuracy: 0.8383\n",
            "Epoch 161/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7654 - accuracy: 0.8359\n",
            "Epoch 162/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7812 - accuracy: 0.8351\n",
            "Epoch 163/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7684 - accuracy: 0.8368\n",
            "Epoch 164/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7603 - accuracy: 0.8355\n",
            "Epoch 165/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7643 - accuracy: 0.8359\n",
            "Epoch 166/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7521 - accuracy: 0.8415\n",
            "Epoch 167/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7496 - accuracy: 0.8393\n",
            "Epoch 168/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7589 - accuracy: 0.8392\n",
            "Epoch 169/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7645 - accuracy: 0.8363\n",
            "Epoch 170/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7631 - accuracy: 0.8358\n",
            "Epoch 171/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7610 - accuracy: 0.8370\n",
            "Epoch 172/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7556 - accuracy: 0.8404\n",
            "Epoch 173/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7646 - accuracy: 0.8357\n",
            "Epoch 174/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7772 - accuracy: 0.8328\n",
            "Epoch 175/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7572 - accuracy: 0.8386\n",
            "Epoch 176/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7555 - accuracy: 0.8388\n",
            "Epoch 177/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7511 - accuracy: 0.8394\n",
            "Epoch 178/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7629 - accuracy: 0.8370\n",
            "Epoch 179/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7570 - accuracy: 0.8391\n",
            "Epoch 180/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7604 - accuracy: 0.8367\n",
            "Epoch 181/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7498 - accuracy: 0.8365\n",
            "Epoch 182/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7575 - accuracy: 0.8348\n",
            "Epoch 183/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7559 - accuracy: 0.8364\n",
            "Epoch 184/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7591 - accuracy: 0.8377\n",
            "Epoch 185/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7582 - accuracy: 0.8382\n",
            "Epoch 186/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7585 - accuracy: 0.8370\n",
            "Epoch 187/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7569 - accuracy: 0.8373\n",
            "Epoch 188/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7600 - accuracy: 0.8362\n",
            "Epoch 189/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7648 - accuracy: 0.8360\n",
            "Epoch 190/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7592 - accuracy: 0.8373\n",
            "Epoch 191/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7495 - accuracy: 0.8390\n",
            "Epoch 192/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7507 - accuracy: 0.8375\n",
            "Epoch 193/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7467 - accuracy: 0.8393\n",
            "Epoch 194/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7470 - accuracy: 0.8383\n",
            "Epoch 195/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7319 - accuracy: 0.8393\n",
            "Epoch 196/200\n",
            "484/484 [==============================] - 5s 10ms/step - loss: 0.7528 - accuracy: 0.8386\n",
            "Epoch 197/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7477 - accuracy: 0.8366\n",
            "Epoch 198/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7537 - accuracy: 0.8373\n",
            "Epoch 199/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7491 - accuracy: 0.8390\n",
            "Epoch 200/200\n",
            "484/484 [==============================] - 5s 11ms/step - loss: 0.7549 - accuracy: 0.8339\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1fXTEO3GJ282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "331a6f63-49c8-458e-b8f7-c6cb26e5cfc9"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEP8PWPX1BCVjdK0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntYhIzCmoRURiTkEtIhJz/w/AG3tfrXby2QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6Vc6PHgxa6Hm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c470045e-8d61-41aa-9ccd-91f39dccb9ba"
      },
      "source": [
        "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = model.predict_classes(token_list, verbose=0)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Help me Obi Wan Kenobi, you're my only hope unseen with crime bow doom and praises still abhor no ill spent ill ill ill ' ' die straight grow days write it hate by me good day truly write her rare ' write it so before still ever from thee die things fell words appear words grow days again so ' are now made another grow new kill me days for thee be me press none bring her rare rare rare bright so rare lie to be or me with thee some one ill ill well remain men now room prove thee ' so short new pride ill ill\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}